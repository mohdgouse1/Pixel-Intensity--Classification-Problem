{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello, I'm glad to be making this kernel for you guys. Hope you understand the steps I have laid out down below.\n\nAnyone with a small experience in image processing, would be aware that the pictures can be represented in the form the pixel intensitites of each pixel.\n\n![](https://thumbs.dreamstime.com/b/nucleolus-hepatocyte-liver-cells-hepatocytes-seen-light-microscope-their-nuclei-show-very-large-stained-red-93292624.jpg)\n\nWhen trying to detect nuclei in a histology picture, it is clear that the nuclei is darker in color than its surroundings. So, the pixel intensities value will differ at the nuclei and the cell space."},{"metadata":{},"cell_type":"markdown","source":"Each row of the file contains pixel intensity values and the final column contains a '0' or a '1' which denotes whether there is any nuclei present in that specific picture."},{"metadata":{},"cell_type":"markdown","source":"Import the necessary libraries as always."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a dataframe by importing all the values from the csv file.\nThis is the main step to perform at the beginning of every data science or machine learning project. This enables us to acess the data at a faster speed and also making sure the original file is safe and unchanged."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the .head() command to confirm the importing of data to the dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, you might think which machine learning algorithms to use. It depends on the ouput. Check the unique entries of the output column which is in question. "},{"metadata":{"trusted":true},"cell_type":"code","source":"list(set(df.Label))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, the output is binary. It is clear that classification algorithms should be employed to solve this task. For this dataset, I'll be using Logistic Regression. You can implement SVM, RandomForest Classifier etc. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split #to split the dataset for training and testing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have just imported the libraries required for Logistic Regression and splitting the dataset for training and testing purpose."},{"metadata":{},"cell_type":"markdown","source":"Let's split the data into training and test datasets as it is important to measure the accuracy of our model with the dataset (test) it has not learned from. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train , test = train_test_split(df, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create training and testing I/O."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop([\"Label\"] , axis = 1)\nY_train = train.Label\n\nX_test = test.drop([\"Label\"] , axis = 1)\nY_test = test.Label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create and define the classifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"Logistic_regressor = LogisticRegression()\nLogistic_regressor.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now when the classifier is fitted with the training data, it has learned the pattern from it. We can go ahead and start predicting with the test dataset input. "},{"metadata":{"trusted":true},"cell_type":"code","source":"Logistic_prediction = Logistic_regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can measure the performance of the classifier by using accuracy and confusion matrix. So let's import the library for it."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \nfrom sklearn import metrics #for checking the model accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find out the confusion matrix and accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"Logistic_cm = confusion_matrix(Y_test, Logistic_prediction)\nLogistic_accuracy = metrics.accuracy_score(Y_test, Logistic_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The accuracy of the classifier is: {}\".format(Logistic_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The Confusion matrix of the classifier is: {}\".format(Logistic_cm))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see the classifier is performing at a very high accuracy. This can be imporved further by using different classification algorithms or ensemble methods.\n\nThank you and let me know how I can improve my explainations."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}